{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Python/Numpy methods/attributes\n",
    "\n",
    "## divmod()\n",
    "\n",
    "Return the tuple (x//y, x%y).\n",
    "\n",
    "```python\n",
    "div, rem = divmod(np.array([11,8,5,1,0]), 3)\n",
    "\n",
    "div\n",
    "array([3, 2, 1, 0, 0], dtype=int32)\n",
    "\n",
    "rem\n",
    "array([2, 2, 2, 1, 0], dtype=int32)\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Series/DataFrame methods/attributes\n",
    "\n",
    "## pd.set_option()\n",
    "\n",
    "pd.set_option(option, val)\n",
    "\n",
    "options: display.max_categories, display.max_columns, display.max_colwidth, display.width, display.precision, display.multi_sparse, ...\n",
    "\n",
    "```python\n",
    "pd.set_option('display.width', 50)\n",
    "```\n",
    "\n",
    "## df.info(), df.describe()\n",
    "\n",
    "* info(): information about a DataFrame including the index dtype and column dtypes, non-null values and memory usage.\n",
    "* describe(): Generate descriptive statistics\n",
    "\n",
    "## Index\n",
    "\n",
    "### indexing a Series\n",
    "\n",
    "```python\n",
    "s # a Series\n",
    "a    2\n",
    "b    5\n",
    "c    8\n",
    "dtype: int64\n",
    "\n",
    "s[0] == s['a']             # True\n",
    "(s[1:] == s['b':]).all()   # True\n",
    "\n",
    "'a' in s.index   # True\n",
    "'a' in s         # True\n",
    "\n",
    "s[3]                # Error\n",
    "s['d']              # Error\n",
    "s.get('d', np.nan)  # nan\n",
    "```\n",
    "\n",
    "### indexing a DataFrame\n",
    "\n",
    "```python\n",
    "df[colname]\n",
    "\n",
    "df[:3]       # slices the rows\n",
    "\n",
    "df.loc['d':, 'A':'C']\n",
    "\n",
    "df.loc[:, df.loc['a'] > 0]\n",
    "\n",
    "df.iloc[[1, 3, 5], [1, 3]]\n",
    "```\n",
    "\n",
    "Change two columns:\n",
    "\n",
    "```python\n",
    "df[['A','B']] = df[['B','A']]\n",
    "```\n",
    "\n",
    "### MultiIndex\n",
    "\n",
    "```python\n",
    "df.columns\n",
    "MultiIndex([('bar', 'one'),\n",
    "            ('bar', 'two'),\n",
    "            ('baz', 'one'),\n",
    "            ('baz', 'two')],\n",
    "           names=['first', 'second'])\n",
    "\n",
    "df['bar']\n",
    "df['bar','one']  #or \n",
    "df[('bar','one')]\n",
    "\n",
    "df[('bar','one'),('baz','two')]    # Error\n",
    "df[[('bar','one'),('baz','two')]]\n",
    "\n",
    "df['one']   # Error\n",
    "df.swaplevel(axis=1)['one']   #or\n",
    "df.loc[:,(slice(None),'one')] #or\n",
    "df.loc(axis=1)[:,'one']       #or\n",
    "df.xs('one',axis=1,level=1)\n",
    "```\n",
    "\n",
    "#### slice()\n",
    "\n",
    "```python\n",
    "df.index\n",
    "MultiIndex([('A0', 'B0', 'C0', 'D0'), ('A0', 'B0', 'C0', 'D1'), ..., ('A3', 'B1', 'C3', 'D1')],)\n",
    "\n",
    "df.columns\n",
    "MultiIndex([('bar', 'one'), ('bar', 'two'), ..., ('qux', 'two')], names=['first', 'second'])\n",
    "\n",
    "df.loc[(slice('A1', 'A3'), slice(None), ['C1', 'C3']), :]\n",
    "# we don't need to have slice(None) for the last level (with values 'D0' and'D1').\n",
    "\n",
    "df.loc['A1', (slice(None), 'foo')]\n",
    "\n",
    "df.loc(axis=0)[:, :, ['C1', 'C3']]\n",
    "```\n",
    "\n",
    "#### pd.IndexSlice\n",
    "\n",
    "```python\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "df.loc[idx[:, :, ['C1', 'C3']], idx[:, 'foo']]\n",
    "\n",
    "df.loc[idx[ df[('a', 'foo')] > 200, :, ['C1', 'C3']], idx[:, 'foo']]\n",
    "```\n",
    "\n",
    "#### xs()\n",
    "\n",
    "xs(key, axis=0, level=None, drop_level=True)\n",
    " \n",
    "```python\n",
    "df.xs('foo', axis=1, level=1)\n",
    "```\n",
    "\n",
    "### swaplevel(), reorder_levels(), rename(), rename_axis()\n",
    "\n",
    "```python\n",
    "df.swaplevel(0, 1, axis=0)\n",
    "```\n",
    "\n",
    "### at(), iat(), get(), lookup()\n",
    "\n",
    "```python\n",
    "s.iat[5]\n",
    "\n",
    "df.at['a', 'B']\n",
    "\n",
    "s.get('x', default=-1)\n",
    "\n",
    "df.lookup([0,4,1], ['B', 'C', 'B'])    # returns np.array([df.at[0,'B'], df.at[4,'C'], df.at[1,'B']])\n",
    "```\n",
    "\n",
    "### isin()\n",
    "\n",
    "```python\n",
    "s[s.isin([2, 4, 6])]\n",
    "\n",
    "# multi-index\n",
    "s.iloc[s.index.isin([(1, 'a'), (2, 'b'), (0, 'c')])]\n",
    "s.iloc[s.index.isin(['a', 'c', 'e'], level=1)]\n",
    "\n",
    "df.isin({'A': ['a', 'b'], 'B': [1, 3]})\n",
    "``` \n",
    "\n",
    "### pd.Index()\n",
    "\n",
    "```python\n",
    "pd.Index(list('abc'))\n",
    "Index(['a', 'b', 'c'], dtype='object')\n",
    "\n",
    "ind = pd.Index(list(range(5)), name='rows')\n",
    "ind.rename(\"apple\")\n",
    "\n",
    "\n",
    "a = pd.Index(['c', 'b', 'a'])\n",
    "b = pd.Index(['c', 'e', 'd'])\n",
    "a | b           # Index(['a', 'b', 'c', 'd', 'e'], dtype='object')\n",
    "a & b           # Index(['c'], dtype='object')\n",
    "a.difference(b) # Index(['a', 'b'], dtype='object')\n",
    "```\n",
    "\n",
    "### set_index(), reset_index(), reindex(), reindex_like()\n",
    "\n",
    "```python\n",
    "df = df.set_index('c')\n",
    "df = df.set_index(['a', 'b'])    # multi-index\n",
    "\n",
    "df.reset_index() # transfers the index values into dfâ€™s columns and sets a simple integer index.\n",
    "df.reset_index(level=1)\n",
    "\n",
    "\n",
    "s\n",
    "a    0\n",
    "b    1\n",
    "c    2\n",
    "dtype: int64\n",
    "    \n",
    "s.reindex(list('bab'))\n",
    "b    1\n",
    "a    0\n",
    "b    1\n",
    "dtype: int64\n",
    "    \n",
    "s.reindex(list('bcad'), fill_value=-np.inf)\n",
    "b    1.0\n",
    "c    2.0\n",
    "a    0.0\n",
    "d   -inf\n",
    "dtype: float64\n",
    "    \n",
    "df\n",
    "   x  y\n",
    "a  0  3\n",
    "b  1  5\n",
    "c  2  1\n",
    "\n",
    "df.reindex(columns=list('yxz'), fill_value=0)\n",
    "   y  x  z\n",
    "a  3  0  0\n",
    "b  5  1  0\n",
    "c  1  2  0\n",
    "```\n",
    "\n",
    "`reindex_like()` returns an object with matching indices as other object. Conform the object to the same index on all axes. \n",
    "\n",
    "```python\n",
    "df1\n",
    "            temp_celsius  temp_fahrenheit windspeed\n",
    "2014-02-12          24.3             75.7      high\n",
    "2014-02-13          31.0             87.8      high\n",
    "2014-02-14          22.0             71.6    medium\n",
    "2014-02-15          35.0             95.0    medium\n",
    "\n",
    "df2\n",
    "            temp_celsius windspeed\n",
    "2014-02-12          28.0       low\n",
    "2014-02-13          30.0       low\n",
    "2014-02-15          35.1    medium\n",
    "\n",
    "df2.reindex_like(df1)\n",
    "            temp_celsius  temp_fahrenheit windspeed\n",
    "2014-02-12          28.0              NaN       low\n",
    "2014-02-13          30.0              NaN       low\n",
    "2014-02-14           NaN              NaN       NaN\n",
    "2014-02-15          35.1              NaN    medium\n",
    "```\n",
    "\n",
    "\n",
    "### where(), mask(), query()\n",
    "\n",
    "```python\n",
    "s.where(s>0)    # same as s[s>0]\n",
    "\n",
    "df[df<0]\n",
    "df.where(df<0, -df)  # if a value in df is not negative, negate the value\n",
    "\n",
    "df\n",
    "   A  B\n",
    "0  0  1\n",
    "1  2  3\n",
    "2  4  5\n",
    "3  6  7\n",
    "4  8  9\n",
    "\n",
    "df.where(df>5, df['A']*10, axis=0)\n",
    "    A   B\n",
    "0   0   0\n",
    "1  20  20\n",
    "2  40  40\n",
    "3   6   7\n",
    "4   8   9\n",
    "```\n",
    "\n",
    "`mask()` is the inverse boolean operation of `where()`.\n",
    "\n",
    "\n",
    "`query()`:\n",
    "\n",
    "```python\n",
    "df.query('A > B')          # A and B are column names.\n",
    "df.query('A == `A 01`')    # A and A 01 are column names.\n",
    "df.query('(a < b) & (b < c)')\n",
    "\n",
    "df.query('index < b < c')  # can use the index name or use 'index'.\n",
    "\n",
    "df.query('a in b')\n",
    "df.query('a not in b')\n",
    "df.query('a in b and c < d')\n",
    "df.query('b == [\"a\", \"b\", \"c\"]')\n",
    "df.query('c != [1, 2]')\n",
    "\n",
    "df.query('~bools')   # df['bools'] is a boolean column\n",
    "df.query('not bools')\n",
    "```\n",
    "\n",
    "### duplicated(), drop_duplicates()\n",
    "\n",
    "`duplicated()` returns a boolean vector whose length is the number of rows, and which indicates whether a row is duplicated.\n",
    "\n",
    "```python\n",
    "df.duplicated('a')\n",
    "\n",
    "df.index.duplicated()\n",
    "```\n",
    "\n",
    "### iterrows()\n",
    "\n",
    "```python\n",
    "df\n",
    "   x  y\n",
    "a  0  3\n",
    "b  1  5\n",
    "c  2  1\n",
    "\n",
    "for t in df:\n",
    "    print(t)\n",
    "x\n",
    "y\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    print(idx)\n",
    "    print(row)\n",
    "    break\n",
    "a\n",
    "x    0\n",
    "y    3\n",
    "Name: a, dtype: int64\n",
    "```\n",
    "\n",
    "\n",
    "## df.insert(), df.assign()\n",
    "\n",
    "insert(loc, column, value, allow_duplicates=False)\n",
    "\n",
    "assign() assigns new columns to a DataFrame and returns a new object with all original columns in addition to new ones. Existing columns that are re-assigned will be overwritten.\n",
    "\n",
    "```python\n",
    "df\n",
    "          temp_c\n",
    "Portland    17.0\n",
    "Berkeley    25.0\n",
    "\n",
    "df.assign(temp_f=df.temp_c*9/5 + 32)   # df.assign(temp_f = lambda x: x.temp_c*9/5+32)\n",
    "          temp_c  temp_f\n",
    "Portland    17.0    62.6\n",
    "Berkeley    25.0    77.0\n",
    "\n",
    "df\n",
    "   temp_c\n",
    "a     0.0\n",
    "b    10.0\n",
    "c    20.0\n",
    "```\n",
    "\n",
    "Be careful when defining a new column using assign():\n",
    "\n",
    "```python\n",
    "df.query('temp_c > 0').assign(log_temp=np.log(df['temp_c']))\n",
    "# RuntimeWarning: divide by zero encountered in log\n",
    "\n",
    "df.query('temp_c > 0').assign(log_temp=lambda x: np.log(x['temp_c'])) # No warning.\n",
    "```\n",
    "\n",
    "## df.lt()\n",
    "\n",
    "lt(other, axis='columns', level=None): less than\n",
    "\n",
    "Among flexible wrappers (eq, ne, le, lt, ge, gt) to comparison operators.\n",
    "\n",
    "Equivalent to ==, =!, <=, <, >=, > with support to choose axis (rows or columns) and level for comparison.\n",
    "\n",
    "\n",
    "## df.all(), df.any(), df.empty\n",
    "\n",
    "all(axis=0, bool_only=None, skipna=True, ...)\n",
    "\n",
    "```python\n",
    "df\n",
    "   col1  col2\n",
    "0     1     4\n",
    "1     2     5\n",
    "2     3     6\n",
    "\n",
    "(df>4).all()        # axis=0 by default\n",
    "col1    False\n",
    "col2    False\n",
    "dtype: bool\n",
    "    \n",
    "(df>4).any()\n",
    "col1    False\n",
    "col2     True\n",
    "dtype: bool\n",
    "    \n",
    "(df>4).any().any()\n",
    "True\n",
    "\n",
    "pd.DataFrame().empty\n",
    "True\n",
    "\n",
    "if df.empty:\n",
    "    # ...\n",
    "```\n",
    "\n",
    "\n",
    "## df.sub(), df.rsub()\n",
    "\n",
    "sub(other, axis='columns', level=None, fill_value=None): Get Subtraction of dataframe and other, element-wise \n",
    "\n",
    "Equivalent to dataframe - other, but with support to substitute a fill_value for missing data in one of the inputs. \n",
    "\n",
    "With reverse version, rsub.\n",
    "\n",
    "Among flexible wrappers (add, sub, mul, div, mod, pow) to arithmetic operators: +, -, *, /, //, %, **.\n",
    "\n",
    "```python\n",
    "df - df['A']      # all entries are NaN; will be deprecated\n",
    "df.sub(df['A'], axis=0)\n",
    "```\n",
    "\n",
    "## ser.str, ser.dt\n",
    "\n",
    "```python\n",
    "s = pd.Series(list('abcb'), dtype='category')\n",
    "s.str.contains('b')\n",
    "s.str.lower()\n",
    "\n",
    "s = pd.Series(pd.date_range('1/1/2020', periods=10))\n",
    "s.dt.day_name()\n",
    "s.dt.year\n",
    "s.dt.strftime('%Y/%m/%d')\n",
    "```\n",
    "\n",
    "## ser.diff()\n",
    "\n",
    "diff(periods=1)\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 1, 2, 3, 5, 8])\n",
    "\n",
    "s.diff().values      # array([nan,  0.,  1.,  1.,  2.,  3.])\n",
    "s.diff(2).values     # array([nan, nan,  1.,  2.,  3.,  5.])\n",
    "s.diff(-1).values    # array([ 0., -1., -1., -2., -3., nan])\n",
    "```\n",
    "\n",
    "It is useful to time series.\n",
    "\n",
    "```python\n",
    "s\n",
    "0   2020-08-07 00:22:41.160568\n",
    "1   2020-08-08 00:13:51.674761\n",
    "2   2020-08-10 00:02:36.000000\n",
    "Name: dates, dtype: datetime64[ns]\n",
    "\n",
    "s.diff()\n",
    "0                      NaT\n",
    "1   0 days 23:51:10.514193\n",
    "2   1 days 23:48:44.325239\n",
    "Name: dates, dtype: timedelta64[ns]\n",
    "```\n",
    "\n",
    "## sort_index(), sort_values(), nsmallest(), nlargest()\n",
    "\n",
    "\n",
    "## sample()\n",
    "\n",
    "sample(n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)\n",
    "\n",
    "Return a random sample of items from an axis of object.\n",
    "\n",
    "```python\n",
    "s.sample(n=3, random_state=1)\n",
    "\n",
    "df.sample(frac=0.5, replace=True, random_state=1)\n",
    "\n",
    "df.sample(n=2, weights='colname', random_state=1)  #  Rows with larger value in a column are more likely to be sampled.\n",
    "```\n",
    "\n",
    "\n",
    "## select_dtypes()\n",
    "\n",
    "select_dtypes(include=None, exclude=None)\n",
    "\n",
    "```python\n",
    "df.select_dtypes(include='bool')\n",
    "df.select_dtypes(include=['float64'])\n",
    "df.select_dtypes(exclude=['int'])\n",
    "```\n",
    "\n",
    "* To select all numeric types, use np.number or 'number'.\n",
    "* To select strings you must use the object dtype, but note that this will return all object dtype columns.\n",
    "* To select datetimes, use np.datetime64, 'datetime' or 'datetime64'.\n",
    "* To select timedeltas, use np.timedelta64, 'timedelta' or 'timedelta64'.\n",
    "* To select Pandas categorical dtypes, use 'category'.\n",
    "\n",
    "\n",
    "## df.pipe()\n",
    "\n",
    "```python\n",
    "def f(df):\n",
    "    # ...\n",
    "    return df\n",
    "def g(df, x):\n",
    "    # ...\n",
    "    return df\n",
    "\n",
    "df.pipe(f).pipe(g, x=5)\n",
    "```\n",
    "\n",
    "## map(), applymap()\n",
    "\n",
    "Apply a function to a Series or Dataframe elementwise.\n",
    "\n",
    "```python\n",
    "s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])\n",
    "\n",
    "s.map({'cat': 'kitten', 'dog': 'puppy'})\n",
    "0    kitten\n",
    "1     puppy\n",
    "2       NaN\n",
    "3       NaN\n",
    "dtype: object\n",
    "    \n",
    "s.map('I am a {}'.format, na_action='ignore')\n",
    "0       I am a cat\n",
    "1       I am a dog\n",
    "2              NaN\n",
    "3    I am a rabbit\n",
    "dtype: object\n",
    "    \n",
    "s.map(len, na_action='ignore')\n",
    "0    3.0\n",
    "1    3.0\n",
    "2    NaN\n",
    "3    6.0\n",
    "dtype: float64\n",
    "    \n",
    "    \n",
    "df.applymap(lambda x: len(str(x)))\n",
    "```\n",
    "\n",
    "## Basic stat functions\n",
    "\n",
    "* sum(), cumsum(), prod(), cumprod()\n",
    "* min(), cummin(), idxmin(), max(), cummax(), idxmax()\n",
    "* count(), value_counts()\n",
    "* mean(), mad(), median(), mode(), abs()\n",
    "* std(), var(), sem() (standard error of the mean)\n",
    "* skew(), kurt(), quantile() \n",
    "\n",
    "* pd.cut()\n",
    "\n",
    "```python\n",
    "#  cut(x, bins, right=True, labels=None, ...)\n",
    "\n",
    "pd.cut(s, 3)     # Discretize into three equal-sized bins.\n",
    "\n",
    "bins = pd.IntervalIndex.from_tuples([(0, 1), (2, 3), (4, 5)])\n",
    "pd.cut([0, 0.5, 1.5, 2.5, 4.5], bins)\n",
    "[NaN, (0, 1], NaN, (2, 3], (4, 5]]\n",
    "                            \n",
    "pd.cut([0, 1, 5, 9, 10], 4)\n",
    "[(-0.01, 2.5], (-0.01, 2.5], (2.5, 5.0], (7.5, 10.0], (7.5, 10.0]]\n",
    "Categories (4, interval[float64]): [(-0.01, 2.5] < (2.5, 5.0] < (5.0, 7.5] < (7.5, 10.0]]\n",
    "\n",
    "pd.qcut([0, 1, 5, 9, 10], 4)   # same as pd.qcut([0, 1, 5, 9, 10], [0, .25, .5, .75, 1])\n",
    "[(-0.001, 1.0], (-0.001, 1.0], (1.0, 5.0], (5.0, 9.0], (9.0, 10.0]]\n",
    "Categories (4, interval[float64]): [(-0.001, 1.0] < (1.0, 5.0] < (5.0, 9.0] < (9.0, 10.0]]                            \n",
    "```\n",
    "\n",
    "## df.to_string(), df.astype()\n",
    "\n",
    "```python\n",
    "df\n",
    "   col1  col2\n",
    "0     1     4\n",
    "1     2     5\n",
    "2     3     6\n",
    "\n",
    "df.to_string()\n",
    "'   col1  col2\\n0     1     4\\n1     2     5\\n2     3     6'\n",
    "\n",
    "df = df.astype({'a': np.bool, 'c': np.float64})\n",
    "```    \n",
    "\n",
    "## pd.read_csv(), df.to_csv()\n",
    "\n",
    "pd.read_csv(filepath_or_buffer, ...)\n",
    "df.to_csv(filepath_or_buffer, ...)\n",
    "\n",
    "```python\n",
    "from io import StringIO\n",
    "\n",
    "buf = StringIO()\n",
    "df.to_csv(buf)\n",
    "df2 = pd.DataFrame(StringIO(buf.getvalue()), index_col=0)\n",
    "```\n",
    "\n",
    "## df.combine_first(), df.combine()\n",
    "\n",
    "```python\n",
    "df1\n",
    "     A    B\n",
    "b  NaN  4.0\n",
    "d  0.0  NaN\n",
    "a  NaN  NaN\n",
    "c  2.0  3.0\n",
    "\n",
    "df2\n",
    "   A  B\n",
    "c  1  3\n",
    "d  1  3\n",
    "\n",
    "df1.combine_first(df2)\n",
    "     A    B\n",
    "a  NaN  NaN\n",
    "b  NaN  4.0\n",
    "c  2.0  3.0\n",
    "d  0.0  3.0\n",
    "```\n",
    "\n",
    "The combine_first() method above calls the more general df.combine()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical data\n",
    "\n",
    "\n",
    "## Creating categorical data type\n",
    "\n",
    "### pd.Categorical()\n",
    "\n",
    "```python\n",
    "x = pd.Categorical(['a', 'b', 'c', 'a', 'b', 'c'], ordered=True, categories=['c', 'b', 'a'])\n",
    "```\n",
    "\n",
    "### Using a Series/DataFrame\n",
    "\n",
    "```python\n",
    "pd.Series([\"a\", \"b\", \"c\", \"a\"], dtype=\"category\")\n",
    "ser.astype('category')\n",
    "\n",
    "pd.DataFrame({'A': list('abca'), 'B': list('xyzz')}, dtype=\"category\")\n",
    "df.astype('category')\n",
    "```\n",
    "\n",
    "### Using CategoricalDtype()\n",
    "\n",
    "```python\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "ser.astype(CategoricalDtype(categories=list('bcd'), ordered=True))\n",
    "df.astype(CategoricalDtype(categories=list('bcd'), ordered=True))   # applied to each column\n",
    "```\n",
    "\n",
    "### Using union_categoricals()\n",
    "\n",
    "union_categoricals(to_union, sort_categories=False, ignore_order=False)\n",
    " \n",
    "```python\n",
    "from pandas.api.types import union_categoricals\n",
    "\n",
    "x = pd.Categorical(list('ab'))\n",
    "y = pd.Categorical(list('bca'))\n",
    "union_categoricals([x,y])\n",
    "[a, b, b, c, a]\n",
    "Categories (3, object): [a, b, c]\n",
    "```\n",
    "\n",
    "\n",
    "### Using special functions\n",
    "\n",
    "```python\n",
    "pd.cut(np.arange(10), [0,4,8,10], right=False)\n",
    "[[0, 4), [0, 4), [0, 4), [0, 4), [4, 8), [4, 8), [4, 8), [4, 8), [8, 10), [8, 10)]\n",
    "Categories (3, interval[int64]): [[0, 4) < [4, 8) < [8, 10)]\n",
    "```\n",
    "\n",
    "## ser.cat\n",
    "\n",
    "* .categories\n",
    "* .ordered\n",
    "* .codes\n",
    "* .rename_categories()\n",
    "* .add_categories()\n",
    "* .remove_categories()\n",
    "* .remove_unused_categories()\n",
    "* .set_categories():  remove and add new categories\n",
    "* .as_ordered()\n",
    "* .as_unordered()\n",
    "* .reorder_categories()\n",
    "\n",
    "```python\n",
    "s = pd.Series([\"a\", \"b\", \"a\"], dtype=\"category\")\n",
    "\n",
    "s.cat.ordered\n",
    "False\n",
    "\n",
    "s.cat.codes         # If s contains NaN, then codes returns -1 for missing values.\n",
    "0    0\n",
    "1    1\n",
    "2    0\n",
    "dtype: int8\n",
    "\n",
    "s.cat.categories\n",
    "Index(['a', 'b'], dtype='object')\n",
    "\n",
    "s.cat.categories = [\"Group %s\" % g for g in s.cat.categories]\n",
    "s\n",
    "0    Group a\n",
    "1    Group b\n",
    "2    Group a\n",
    "dtype: category\n",
    "Categories (2, object): [Group a, Group b]\n",
    "    \n",
    "s.cat.rename_categories([1,2])\n",
    "0    1\n",
    "1    2\n",
    "2    1\n",
    "dtype: category\n",
    "Categories (2, int64): [1, 2]\n",
    "    \n",
    "s.cat.set_categories([0, 1], ordered=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping\n",
    "\n",
    "\n",
    "## groupby()\n",
    "\n",
    "groupby(by=None, axis=0, level=None, as_index=True, ...)\n",
    "\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame(np.arange(16).reshape(4,4), columns=list('ABUV'), index=pd.MultiIndex.from_product([['a','b'],['u','v']]))\n",
    "\n",
    "df\n",
    "      A   B   U   V\n",
    "a u   0   1   2   3\n",
    "  v   4   5   6   7\n",
    "b u   8   9  10  11\n",
    "  v  12  13  14  15\n",
    "    \n",
    "for name, gp in df.groupby(level=0): print(name); print(gp); break\n",
    "a\n",
    "     A  B  U  V\n",
    "a u  0  1  2  3\n",
    "  v  4  5  6  7\n",
    "    \n",
    "for name, gp in df.groupby(['v','c','v','c'], axis=1): print(name); print(gp); break\n",
    "c\n",
    "      B   V\n",
    "a u   1   3\n",
    "  v   5   7\n",
    "b u   9  11\n",
    "  v  13  15\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agg(), apply(), filter(), transform() \n",
    "\n",
    "* agg(): The function used in agg() is applied to each column and returns a scalar value.\n",
    "\n",
    "```python\n",
    "df.agg(['sum', 'mean'])\n",
    "df.agg({'A': 'mean', 'B': 'sum'})\n",
    "\n",
    "from functools import partial\n",
    "q_25 = partial(pd.Series.quantile, q=0.25)\n",
    "q_75 = partial(pd.Series.quantile, q=0.75)\n",
    "df.agg(['mean', 'std', q_25, q_75])\n",
    "```\n",
    "\n",
    "* apply(): The function used in apply() is applied to each subframe and returns a dataframe, a series or a scalar. While apply is a very flexible method, its downside is that using it can be quite a bit slower than using more specific methods like agg or transform. Pandas offers a wide range of method that will be much faster than using apply for their specific purposes, so try to use them before reaching for apply.\n",
    "\n",
    "\n",
    "* transform(): The function used in transform() is applied to each column and returns a Series having the same indexes as the original object filled with the transformed values.\n",
    "\n",
    "```python\n",
    "df.transform([np.abs, lambda x: x + 1])\n",
    "df.transform({'A': np.abs, 'B': lambda x: x + 1})\n",
    "```\n",
    "\n",
    "* filter(): The function used in filter() is applied to each subframe and returns True or False.\n",
    "\n",
    "\n",
    "```python\n",
    "df\n",
    "   A  B     C\n",
    "0  1  1  1.82\n",
    "1  1  2 -0.87\n",
    "2  2  3  0.35\n",
    "3  2  4 -1.26\n",
    "\n",
    "\n",
    "df.groupby('A').agg(['min', 'max'])\n",
    "    B         C      \n",
    "  min max   min   max\n",
    "A                    \n",
    "1   1   2 -0.87  1.82\n",
    "2   3   4 -1.26  0.35\n",
    "\n",
    "\n",
    "def f(x): x['C'] = x['C']/x['B']**2; return x\n",
    "df.groupby('A').apply(f)\n",
    "   A  B         C\n",
    "0  1  1  1.820000\n",
    "1  1  2 -0.217500\n",
    "2  2  3  0.038889\n",
    "3  2  4 -0.078750\n",
    "\n",
    "\n",
    "df.groupby('A').filter(lambda x: x['B'].mean() > 2)\n",
    "   A  B     C\n",
    "2  2  3  0.35\n",
    "3  2  4 -1.26\n",
    "\n",
    "\n",
    "df.groupby('A').transform(lambda x: x - x.mean())\n",
    "     B      C\n",
    "0 -0.5  1.345\n",
    "1  0.5 -1.345\n",
    "2 -0.5  0.805\n",
    "3  0.5 -0.805\n",
    "\n",
    "\n",
    "# Here ts is a DataFrame whose index is of type DatetimeIndex.\n",
    "ts.groupby(lambda x: x.year).transform(lambda x: x.max() - x.min())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rolling(), expanding()\n",
    "    \n",
    "```python    \n",
    "df = pd.DataFrame({'A': [1] * 4 + [5] * 4, 'B': range(8)})\n",
    "\n",
    "df.groupby('A').B.rolling(2).sum()\n",
    "A   \n",
    "1  0     NaN\n",
    "   1     1.0\n",
    "   2     3.0\n",
    "   3     5.0\n",
    "5  4     NaN\n",
    "   5     9.0\n",
    "   6    11.0\n",
    "   7    13.0\n",
    "Name: B, dtype: float64\n",
    "\n",
    "        \n",
    "df.groupby('A').B.expanding(2).sum()\n",
    "A   \n",
    "1  0     NaN\n",
    "   1     1.0\n",
    "   2     3.0\n",
    "   3     6.0\n",
    "5  4     NaN\n",
    "   5     9.0\n",
    "   6    15.0\n",
    "   7    22.0\n",
    "Name: B, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pd.Grouper()\n",
    "\n",
    "A Grouper allows the user to specify a groupby instruction for a target object.\n",
    "\n",
    "```python\n",
    "df\n",
    "     A   B   U\n",
    "a u  3   1   2\n",
    "  v  7   5   6\n",
    "b u  7   9  10\n",
    "  v  3  13  14\n",
    "\n",
    "df.groupby([pd.Grouper(level=1), 'A']).sum()\n",
    "      B   U\n",
    "  A        \n",
    "u 3   1   2\n",
    "  7   9  10\n",
    "v 3  13  14\n",
    "  7   5   6\n",
    "\n",
    "# Specify a resample operation on the column 'date' with a frequency of 60s\n",
    "df.groupby(Grouper(key='date', freq='60s'))\n",
    "\n",
    "# Specify a resample operation on the level 'date' on the columns axis with a frequency of 60s\n",
    "df.groupby(Grouper(level='date', freq='60s', axis=1))\n",
    "```\n",
    "\n",
    "\n",
    "## Other functions used in groups\n",
    "\n",
    "### first(), last(), head(), tail(), nth()\n",
    "\n",
    "\n",
    "### nlargest(), nsmallest()\n",
    "\n",
    "\n",
    "### shift()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide format, Long format\n",
    "\n",
    "\n",
    "## stack(), unstack()\n",
    "\n",
    "* stack(level=-1, dropna=True): Stack the prescribed level(s) from columns to index.\n",
    "* unstack(level=-1, fill_value=None): Unstack Series with MultiIndex to produce DataFrame. \n",
    "\n",
    "```python\n",
    "s = pd.Series(range(4), index=pd.MultiIndex.from_product([['A','B'],['a','b']]))\n",
    "s\n",
    "A  a    0\n",
    "   b    1\n",
    "B  a    2\n",
    "   b    3\n",
    "    \n",
    "s.unstack()\n",
    "   a  b\n",
    "A  0  1\n",
    "B  2  3\n",
    "\n",
    "s.unstack().stack()    # same as s\n",
    "```\n",
    "\n",
    "## melt(), pivot()\n",
    "\n",
    "* melt(id_vars, value_vars, ...)\n",
    "* pivot(index, columns, values)\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'A': list('abc'), 'B':[1,3,5],'C':[2,4,6]})\n",
    "df\n",
    "   A  B  C\n",
    "0  a  1  2\n",
    "1  b  3  4\n",
    "2  c  5  6\n",
    "\n",
    "df = df.melt(id_vars='A', value_vars='B')\n",
    "df\n",
    "   A variable  value\n",
    "0  a        B      1\n",
    "1  b        B      3\n",
    "2  c        B      5\n",
    "\n",
    "df2 = df.melt(id_vars='A', value_vars=['B','C'])\n",
    "df2\n",
    "   A variable  value\n",
    "0  a        B      1\n",
    "1  b        B      3\n",
    "2  c        B      5\n",
    "3  a        C      2\n",
    "4  b        C      4\n",
    "5  c        C      6\n",
    "\n",
    "df2.pivot(index='A', columns='variable', values='value')\n",
    "variable  B  C\n",
    "A             \n",
    "a         1  2\n",
    "b         3  4\n",
    "c         5  6\n",
    "```\n",
    "\n",
    "\n",
    "## pivot_table()\n",
    "\n",
    "pivot_table = pivot + aggregate function\n",
    "\n",
    "pivot_table(values, index, columns, aggfunc, fill_value, margins, dropna, ...)\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'A': ['foo',]*5+['bar',]*4, \n",
    "                  'B': np.array(['one','two'])[[0,0,0,1,1,0,0,1,1]], \n",
    "                  'C': np.array(['small','large'])[[0,1,1,0,0,1,0,0,1]],\n",
    "                  'D': [1,2,2,3,3,4,5,6,7],\n",
    "                  'E': [2,3,5,5,6,6,8,9,9]})\n",
    "\n",
    "df\n",
    "     A    B      C  D  E\n",
    "0  foo  one  small  1  2\n",
    "1  foo  one  large  2  3\n",
    "2  foo  one  large  2  5\n",
    "3  foo  two  small  3  5\n",
    "4  foo  two  small  3  6\n",
    "5  bar  one  large  4  6\n",
    "6  bar  one  small  5  8\n",
    "7  bar  two  small  6  9\n",
    "8  bar  two  large  7  9\n",
    "\n",
    "df.pivot_table(values='D', index=['A','B'], columns=['C'], aggfunc=np.sum)\n",
    "C        large  small\n",
    "A   B                \n",
    "bar one    4.0    5.0\n",
    "    two    7.0    6.0\n",
    "foo one    4.0    1.0\n",
    "    two    NaN    6.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular expressions\n",
    "\n",
    "\n",
    "## \\\\*number*\n",
    "\n",
    "\\\\*number* is a backreference. For example, \\1 is the first parentheses-delimited expression inside of the regex.\n",
    "\n",
    "```python\n",
    "import re\n",
    "re.sub(r\"([?.,!])\", r\" \\1 \", \"He's good,, but not always..\")       # \"He's good ,  ,  but not always .  . \"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IO\n",
    "\n",
    "## read_csv()\n",
    "\n",
    "* When column 'dob' contains timestamp values:\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('my_file.csv', parse_dates=['dob',])\n",
    "```\n",
    "\n",
    "* If we want column 'dob' to be the index:\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('my_file.csv', index_col='dob', parse_dates=['dob',])\n",
    "\n",
    "# or we can use the position of the column in index_col=\n",
    "```\n",
    "\n",
    "* Consider the file test.csv with lines:\n",
    "\n",
    "    \"Date\", \"Values\"\n",
    "\n",
    "    \"1-01\", 12.0\n",
    "\n",
    "    \"1-02\", 8.2\n",
    "\n",
    "    \"1-03\", 9.4\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('test.csv', index_col=0, parse_dates=True,  \n",
    "            date_parser=lambda x: pd.datetime.strptime(\"200\"+x, \"%Y-%m\"), squeeze=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
